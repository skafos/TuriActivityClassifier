{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Activity Data Integration**\n",
    "This notebook is intended to show you how you might train your own model on activity data. In this example, we took some data from [Viktor Malyi's 4 part article](https://towardsdatascience.com/run-or-walk-detecting-user-activity-with-machine-learning-and-core-ml-part-1-9658c0dcdd90) and formatted it such that the TuriCreate activity classifier function could accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies (make sure you have installed them first)\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import turicreate as tc\n",
    "from skafossdk import *\n",
    "\n",
    "ska = Skafos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read the Data**\n",
    "For simplicity, we loaded the data into an S3 bucket but the original source is [Viktor Malyi's Kaggle submission](https://www.kaggle.com/vmalyi/run-or-walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url = \"https://s3.amazonaws.com/skafos.example.data/ActivityClassifier/running_walking.csv\"\n",
    "data = pd.read_csv(s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n",
    "We do some basic data cleaning to get it in a format for the Turi Create activity classification model\n",
    "\n",
    "- The major requirements for the Turi Create function are a *session_id* and *activity label*.\n",
    "- A session can be thought of as an experiment where the data is being collected by a single user on various activities (not limited to one). \n",
    "\n",
    "Because we have timestamps and not session ids, we try to back into a session column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the activities to names\n",
    "activity_map = {1: 'running', 0: 'walking'}\n",
    "data['activity'] = data['activity'].apply(lambda x: activity_map[x])\n",
    "\n",
    "# Clean up the date time field\n",
    "data['time'] = data['time'].astype(str).apply(lambda x: \":\".join(x.split(\":\")[0:3]))\n",
    "data['date_time'] = data['date'] + \" \" + data['time']\n",
    "data['date_time'] = data['date_time'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect changes\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below is a function that:\n",
    "- takes as input a dataframe\n",
    "- a datetime column name\n",
    "- an activity column name\n",
    "- returns the same dataframe with a 'session_id' column.\n",
    "\n",
    "The function takes each row and assigns it a session based on how soon that record was timestamped after the previous record (controlling for actvity type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session_ids(df, time_col, activity_col, threshold=10):\n",
    "    \n",
    "    # Sort the dataframe by activity and time, add an index column\n",
    "    temp_df = df.sort_values(by=[activity_col, time_col]).reset_index(drop=False)\n",
    "    \n",
    "    # Create a list of index, time, activity objects\n",
    "    recs = list(temp_df.apply(lambda x: {'index': x['index'], time_col:  x[time_col], activity_col: x[activity_col]}, axis=1))\n",
    "    sessions = []\n",
    "    session_id = 0\n",
    "    # Loop over the time, activity objects, assign \"session ids\" to those records that are within the time threshold\n",
    "    for i in range(len(recs)):\n",
    "        if (recs[i][time_col] - recs[i-1][time_col]).total_seconds() < threshold and recs[i][activity_col] == recs[i-1][activity_col]:\n",
    "            recs[i]['session_id'] = session_id\n",
    "            sessions.append(recs[i])\n",
    "        else:\n",
    "            session_id +=1 # up the session id\n",
    "            recs[i]['session_id'] = session_id\n",
    "            sessions.append(recs[i])\n",
    "    \n",
    "    # Convert back to df, merge with original df \n",
    "    session_df = pd.DataFrame.from_records(sessions)\n",
    "    merged_df = pd.merge(temp_df, session_df, on = ['index', time_col, activity_col], how = 'left')\n",
    "    \n",
    "    # Clean up the dataframe\n",
    "    del merged_df['index']\n",
    "    \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we generate the session ids and assign it back to the variable **`data`**. \n",
    "- Finally we convert to an **`SFrame`**, the a TuriCreate data type similar to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_session_ids(data, 'date_time', 'activity')\n",
    "data = data[['session_id', 'activity', 'acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "print(f\"The data has dimensions {data.shape} (rows x columns)\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the sessions by activity type - mostly running\n",
    "data.groupby(['activity']).agg({'session_id' : pd.Series.nunique})/data['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sessions from the dataframe to reduce the training data size\n",
    "unique_sessions = len(data['session_id'].unique())\n",
    "n_session_samples = int(unique_sessions * 0.5)\n",
    "print(f\"There are {unique_sessions} sessions\", flush=True)\n",
    "print(f\"Sampling {n_session_samples} sessions due to memory constraints\", flush=True)\n",
    "session_sample = pd.Series(data['session_id'].unique()).sample(n_session_samples)\n",
    "\n",
    "# Create a dataframe of sampled data\n",
    "sample_data = data[data['session_id'].isin(session_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the sampled sessions by activity type - still mostly running\n",
    "sample_data.groupby(['activity']).agg({'session_id' : pd.Series.nunique})/sample_data['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to SFrame because that's what Turi Create needs\n",
    "sample_data_sframe = tc.SFrame(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train the Model**\n",
    "\n",
    "The following is the same code as in the example. We have replaced the session_id argument and target argument with the appropriate column names in our new dataframe.\n",
    "\n",
    "Steps:\n",
    "- Split into training and testing\n",
    "- Create the model (model build)\n",
    "- Evaluate the model on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tc.activity_classifier.util.random_split_by_session(\n",
    "    dataset=sample_data_sframe,\n",
    "    session_id='session_id',\n",
    "    fraction=0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tc.activity_classifier.create(\n",
    "    dataset=train_data,\n",
    "    session_id='session_id',\n",
    "    target='activity',\n",
    "    prediction_window=50 # We want 1 prediction per second.. so prediction_window = (1 pred/sec) * (50 Hz) = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Evaluation**\n",
    "Now we evaluate our model against some testing data. First, we grab some slices of data where walking and running took place and see if the model correctly classifies those activities. Then we evaluation the model against the entire testing set, computing an accuracy benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 3 seconds of walking data constrained to a single experiment where walking took place\n",
    "exp_id_with_walking = test_data[test_data['activity'] == 'walking']['session_id'].value_counts()[0]['value']\n",
    "walking_3_seconds = test_data[(test_data['activity'] == 'walking') & (test_data['session_id'] == exp_id_with_walking)][:150]\n",
    "\n",
    "# Find 10 seconds of running data constrained to a single experiment where running took place\n",
    "exp_id_with_running = test_data[test_data['activity'] == 'running']['session_id'].value_counts()[0]['value']\n",
    "running_10_seconds = test_data[(test_data['activity'] == 'running') & (test_data['session_id'] == exp_id_with_running)][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model properly classifies each second as walking or something else\n",
    "model.predict(walking_3_seconds, output_frequency='per_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model properly classifies each second as running or something else\n",
    "model.predict(running_10_seconds, output_frequency='per_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy of the model against the entire hold out testing set\n",
    "accuracy = tc.evaluation.accuracy(test_data['activity'], model.predict(test_data))\n",
    "print(f'The activity classifier predicted {accuracy*100} % of the testing observations correctly!', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
